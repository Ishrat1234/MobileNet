{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.optimizers import Adam, SGD\nimport random\n\nfrom keras.layers import Flatten, Dropout, BatchNormalization, Reshape, GlobalAveragePooling2D\nfrom keras.layers import Dense, Dropout, Input\nfrom keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom keras.preprocessing import image\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nimport shutil\n\nimport matplotlib.image as mpimg\n%matplotlib inline","metadata":{"id":"7cOVSMy2OkZe","outputId":"b6f61554-cac6-4023-b304-9c554ac7fca4","execution":{"iopub.status.busy":"2023-03-23T21:11:38.542752Z","iopub.execute_input":"2023-03-23T21:11:38.543162Z","iopub.status.idle":"2023-03-23T21:11:46.390799Z","shell.execute_reply.started":"2023-03-23T21:11:38.543128Z","shell.execute_reply":"2023-03-23T21:11:46.389635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# total_images = 27558\n# validation_size = 0.20\n\n# training_parasitized_folder_name = \"training/Parasitized\"\n# training_uninfected_folder_name = \"training/Uninfected\"\n\n# validation_parasitized_folder_name = \"validation/Parasitized\"\n# validation_uninfected_folder_name = \"validation/Uninfected\"","metadata":{"id":"6sWAG43ZKTqE","execution":{"iopub.status.busy":"2023-03-23T21:11:46.392973Z","iopub.execute_input":"2023-03-23T21:11:46.393726Z","iopub.status.idle":"2023-03-23T21:11:46.401046Z","shell.execute_reply.started":"2023-03-23T21:11:46.393685Z","shell.execute_reply":"2023-03-23T21:11:46.399951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# parasitized_folder = os.listdir(\"training/Parasitized\")\n# uninfected_folder = os.listdir(\"training/Uninfected\")\n\n# validation_folder_size = int(len(parasitized_folder) * 0.20)\n\n# for image_name in parasitized_folder[:validation_folder_size]:\n#     image_url = f'{training_parasitized_folder_name}/{image_name}'\n#     shutil.move(image_url, validation_parasitized_folder_name)\n  \n# for image_name in uninfected_folder[:validation_folder_size]:\n#     image_url = f'{training_uninfected_folder_name}/{image_name}'\n#     shutil.move(image_url, validation_uninfected_folder_name)","metadata":{"id":"AoY641AAOntt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def plot_images(image_index, folder_name, image_name, title):\n#   sp = figure.add_subplot(2, 3, image_index + 1)\n#   sp.axis('Off')\n#   image_path = f'{folder_name}/{image_name}'\n#   image_loaded = img=mpimg.imread(image_path)\n#   sp.set_title(title, fontsize=16)\n#   plt.imshow(image_loaded, interpolation=None)\n\n# figure = plt.figure(figsize=(12, 6))\n# parasitized_images = os.listdir(\"training/Parasitized\")[0:3]\n# uninfected_images = os.listdir(\"training/Uninfected\")[0:3]\n\n# for image_index, image_name in enumerate(parasitized_images):\n#   plot_images(image_index, training_parasitized_folder_name, image_name, \"Parasitized\")\n\n# for image_index, image_name in enumerate(uninfected_images):\n#   plot_images(image_index + 3, training_uninfected_folder_name, image_name, \"Uninfected\")","metadata":{"id":"ustDT04RxVBk","outputId":"2fe740c3-bb59-426a-e1df-692705c81de9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_size = 96\ninput_img_size = (96, 96, 3)\nnum_classes = 2\ntotal_images = 27558","metadata":{"id":"GyCEcpD1dbNs","execution":{"iopub.status.busy":"2023-03-23T21:11:46.40278Z","iopub.execute_input":"2023-03-23T21:11:46.403258Z","iopub.status.idle":"2023-03-23T21:11:46.429684Z","shell.execute_reply.started":"2023-03-23T21:11:46.403217Z","shell.execute_reply":"2023-03-23T21:11:46.428495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rotation_range=20,\n    zoom_range=0.05,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    shear_range=0.05,\n    horizontal_flip=True,\n    fill_mode=\"nearest\",\n     validation_split=0.2)\ntrain_generator = datagen.flow_from_directory(\n    \"../input/cell-images-for-detecting-malaria/cell_images/cell_images/\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",\n\t  shuffle=True,\n    batch_size=batch_size, subset='training')\n\n\nval_generator = datagen.flow_from_directory(\n    \"../input/cell-images-for-detecting-malaria/cell_images/cell_images/\",\n    target_size=(img_size, img_size),\n    color_mode=\"rgb\",\n\t  shuffle=False,\n    batch_size=batch_size,subset='validation')","metadata":{"id":"MDn9jAENcPNa","outputId":"3889d894-ac71-473f-a9c9-0dafce4723ee","execution":{"iopub.status.busy":"2023-03-23T21:11:49.081676Z","iopub.execute_input":"2023-03-23T21:11:49.082497Z","iopub.status.idle":"2023-03-23T21:12:12.291426Z","shell.execute_reply.started":"2023-03-23T21:11:49.082444Z","shell.execute_reply":"2023-03-23T21:12:12.290239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator","metadata":{"execution":{"iopub.status.busy":"2023-03-23T21:12:12.293444Z","iopub.execute_input":"2023-03-23T21:12:12.294602Z","iopub.status.idle":"2023-03-23T21:12:12.304248Z","shell.execute_reply.started":"2023-03-23T21:12:12.29456Z","shell.execute_reply":"2023-03-23T21:12:12.303016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_steps = int((total_images - (total_images//2*0.2 * 2)) // batch_size)\nval_steps = int((total_images//2*0.2 * 2) // batch_size) ","metadata":{"id":"3pXmtLx-egG0","execution":{"iopub.status.busy":"2023-03-23T21:12:12.305912Z","iopub.execute_input":"2023-03-23T21:12:12.306366Z","iopub.status.idle":"2023-03-23T21:12:12.321627Z","shell.execute_reply.started":"2023-03-23T21:12:12.306322Z","shell.execute_reply":"2023-03-23T21:12:12.320311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{"id":"pTzgWWg3cMh_"}},{"cell_type":"code","source":"def create_model():\n  input_tensor = Input(shape=input_img_size)\n  \n  mobile_model = MobileNetV2(\n       weights=None,\n       input_tensor=input_tensor,\n       input_shape=input_img_size,\n       alpha=1.5,\n       include_top=False)\n  \n  for layer in mobile_model.layers:\n    layer.trainable = True\n  \n  mobile_model_output = mobile_model.output\n  classification_layer = Flatten()(mobile_model_output)\n  classification_layer = Dense(256, activation='relu')(classification_layer)\n  classification_layer = Dropout(0.5)(classification_layer)\n  predictions = Dense(activation=\"softmax\", units=num_classes)(classification_layer)\n\n  model = Model(inputs=input_tensor, outputs=predictions)\n  \n  return model","metadata":{"id":"_qDkec1qOnwV","execution":{"iopub.status.busy":"2023-03-23T21:12:15.59558Z","iopub.execute_input":"2023-03-23T21:12:15.596099Z","iopub.status.idle":"2023-03-23T21:12:15.6042Z","shell.execute_reply.started":"2023-03-23T21:12:15.596034Z","shell.execute_reply":"2023-03-23T21:12:15.602586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 3e-4\nepochs = 30","metadata":{"id":"Xm6NL_Rt_q-Q","execution":{"iopub.status.busy":"2023-03-23T21:12:17.03685Z","iopub.execute_input":"2023-03-23T21:12:17.037383Z","iopub.status.idle":"2023-03-23T21:12:17.042703Z","shell.execute_reply.started":"2023-03-23T21:12:17.037316Z","shell.execute_reply":"2023-03-23T21:12:17.041551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polynomial_decay(epoch):\n\tpower = 1.0\n \n\talpha = learning_rate * (1 - (epoch / float(epochs))) ** power\n\treturn alpha","metadata":{"id":"VP1G8n1J_kK9","execution":{"iopub.status.busy":"2023-03-23T21:12:17.624755Z","iopub.execute_input":"2023-03-23T21:12:17.625137Z","iopub.status.idle":"2023-03-23T21:12:17.630422Z","shell.execute_reply.started":"2023-03-23T21:12:17.6251Z","shell.execute_reply":"2023-03-23T21:12:17.629173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_name = \"epoch={epoch:02d}|accuracy={val_acc:.4f}.h5\"\n\ncheckpoint = ModelCheckpoint(weights_name, monitor=\"val_acc\", verbose=1, save_best_only=True,\n                                 save_weights_only=True, mode=\"max\", period=1)\n\nlr_decay = LearningRateScheduler(polynomial_decay)\n\noptimizer = SGD(lr=learning_rate, momentum=0.9)","metadata":{"id":"fuXXjEsxd9MO","outputId":"51a575be-2fe7-4fc6-9dee-ecdbc8a23b2c","execution":{"iopub.status.busy":"2023-03-23T21:12:19.787081Z","iopub.execute_input":"2023-03-23T21:12:19.788016Z","iopub.status.idle":"2023-03-23T21:12:19.805198Z","shell.execute_reply.started":"2023-03-23T21:12:19.787962Z","shell.execute_reply":"2023-03-23T21:12:19.804011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])","metadata":{"id":"sTnGeGnSeD3u","outputId":"d6b2e521-4dbd-46bb-d7f4-a3df212d0f05","execution":{"iopub.status.busy":"2023-03-23T21:12:21.88309Z","iopub.execute_input":"2023-03-23T21:12:21.883453Z","iopub.status.idle":"2023-03-23T21:12:25.723313Z","shell.execute_reply.started":"2023-03-23T21:12:21.88342Z","shell.execute_reply":"2023-03-23T21:12:25.722269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model = model.fit_generator(train_generator,\n                        epochs=epochs,\n                        steps_per_epoch=train_steps,\n#                         batch_size = 64,\n                        callbacks=[checkpoint, lr_decay],\n                        validation_data=val_generator,\n                        validation_steps=val_steps,\n                        verbose=1)","metadata":{"id":"vY90zZuMeQ39","outputId":"add10c2e-beb6-4be8-e0c2-672b67011d6e","execution":{"iopub.status.busy":"2023-03-23T21:12:39.876278Z","iopub.execute_input":"2023-03-23T21:12:39.876646Z","iopub.status.idle":"2023-03-23T21:23:09.162569Z","shell.execute_reply.started":"2023-03-23T21:12:39.876612Z","shell.execute_reply":"2023-03-23T21:23:09.160743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_validation_training(metric, trained_model):\n  validation_metric = trained_model.history[f'val_{metric}']\n  training_metric = trained_model.history[metric]\n  epochs = range(len(training_metric))\n  plt.plot(epochs, training_metric, 'b', label=f'Training {metric}')\n  plt.plot(epochs, validation_metric, 'r', label=f'Validation {metric}')\n  plt.ylim(bottom=0)\n  plt.xlabel('Epochs ', fontsize=16)\n  plt.ylabel(metric, fontsize=16)\n  loc = 'upper right' if metric == \"loss\" else 'lower right'\n  plt.legend(loc=loc)\n  plt.title(f'Training and validation {metric}', fontsize = 20)\n  plt.show()","metadata":{"id":"UVUAGt8Nebrv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_validation_training(\"loss\", trained_model)","metadata":{"id":"Zwa0gO2HfTUr","outputId":"2bf32247-f06c-4598-c8d5-e0850dface5f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_validation_training(\"acc\", trained_model)","metadata":{"id":"bvTr_zfDfUnp","outputId":"47a59134-28df-408a-a2ab-94c1f6dc9aa0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","metadata":{"id":"Dx-Md8JlfVdA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"epoch=24_accuracy=0.9646.h5\")","metadata":{"id":"RPtXg_FpnzIb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator.reset()","metadata":{"id":"Tk_B55eHqce_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_predicted = model.predict_generator(val_generator, steps=val_steps, verbose=1)","metadata":{"id":"wNRkXXNlfYSz","outputId":"55386be3-c0ac-4609-d79c-713ec97e8333","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(classes_predicted)","metadata":{"id":"sjCr5kgTrVHl","outputId":"03152689-638e-4ab8-d132-68c5591e0c45","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_classes = np.argmax(classes_predicted, axis=1)","metadata":{"id":"9ABglfFCpcFv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_labels = val_generator.classes","metadata":{"id":"ujAU8hbH9iZ_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_labels = val_labels[:5504]","metadata":{"id":"343j8zuf6OQ2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(val_labels), len(real_classes)","metadata":{"id":"Ztn8mmKjm0lO","outputId":"134fa25e-304c-45a6-8d3a-277638bd8a7c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_generator.class_indices","metadata":{"id":"MwZiAc4U9r4c","outputId":"80b82112-fc0c-4599-9537-8033e76b819c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_names = [\"Parasitized\", \"Uninfected\"]","metadata":{"id":"TNAkR5yE96CO","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(val_labels, real_classes, labels=range(num_classes))\nplot_confusion_matrix(cm, classes_names)","metadata":{"id":"QJhme_pkfaBq","outputId":"db57d47d-5ba6-454f-89d6-df587b5acf18","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\nprint(f'sensitivity: {sensitivity}')\n\nspecificity = cm[1, 1] / (cm[1, 1] + cm[1, 0])\nprint(f'specifity: {specificity}')","metadata":{"id":"B5wSUcpI6UGZ","outputId":"828e7c57-10b6-40da-e03a-eb29c133d080","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report","metadata":{"id":"7nNL0BnnuScU","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = classification_report(val_labels, real_classes, target_names=classes_names)\nprint(report)","metadata":{"id":"kpcwB58A67E0","outputId":"33524661-58fe-4d05-cf4c-2cb365eb48ce","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gradient maps","metadata":{"id":"QnwrBw8_rA7f"}},{"cell_type":"code","source":"!pip uninstall keras-vis","metadata":{"id":"pL-33OpiJ2vV","outputId":"45a4ce17-aa06-4039-a38b-f595cf8566ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/raghakot/keras-vis.git -U","metadata":{"id":"ibutHUobH11v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vis.visualization import visualize_saliency, overlay\nfrom vis.utils import utils\nfrom keras import activations","metadata":{"id":"Tm52EDfFKp1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parasitized_folder = os.listdir(\"training/Parasitized\")\nuninfected_folder = os.listdir(\"training/Uninfected\")","metadata":{"id":"5VkHqcfKKpzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parasitized_image_path = f'{training_parasitized_folder_name}/{parasitized_folder[20]}'\nuninfected_image_path = f'{training_uninfected_folder_name}/{uninfected_folder[20]}'\n\nparasitized_image = utils.load_img(parasitized_image_path, target_size=(96, 96))\nuninfected_image = utils.load_img(uninfected_image_path, target_size=(96, 96))","metadata":{"id":"jWEabmo2FY5z","outputId":"f3c12483-6141-4e54-cecf-3a702a4b6f36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parasitized_image_model = image.load_img(parasitized_image_path, target_size=(96, 96))\nuninfected_image_model = image.load_img(uninfected_image_path, target_size=(96, 96))\n\nparasitized_image_model = image.img_to_array(parasitized_image)\nparasitized_image_model = preprocess_input(parasitized_image)\n\nuninfected_image_model = image.img_to_array(uninfected_image)\nuninfected_image_model = preprocess_input(uninfected_image)\n\npreprocessed_images = np.array([parasitized_image_model, uninfected_image_model])","metadata":{"id":"Z_TkW-PPRWav"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(preprocessed_images)","metadata":{"id":"3Q0ZP69TR_jn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_classes = np.argmax(predictions, axis=1)","metadata":{"id":"4X__j95ySCug"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_array = [parasitized_image, uninfected_image]","metadata":{"id":"QUREgKHSMyoR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(8, 8))\nfig.suptitle('Normal Images')\n\nfor index, img in enumerate(images_array):   \n  class_index = predicted_classes[index]\n  ax[index].set_title(f'class: {classes_names[index]}, pred: {classes_names[class_index]}')\n  ax[index].imshow(img)","metadata":{"id":"LI1U04qrLedU","outputId":"4c8ffccb-6c4c-4b82-8fff-339dba86af29"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_idx = utils.find_layer_idx(model, 'dense_2')\n\nfig, ax = plt.subplots(1, 2, figsize=(8, 8))\nfig.suptitle('Gradient maps')\n\nfor index, img in enumerate(images_array):    \n    grads = visualize_saliency(model, layer_idx, filter_indices=index, seed_input=img)\n    ax[index].set_title(classes_names[index])\n    ax[index].imshow(grads, cmap='jet')","metadata":{"id":"ZfUbAhvjGLgo","outputId":"94019281-30c5-411c-e6e4-88aa54049dfb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for modifier in ['guided', 'relu']:\n    plt.figure()\n    f, ax = plt.subplots(1, 2)\n    plt.suptitle(modifier)\n    \n    for index, img in enumerate(images_array):    \n        grads = visualize_saliency(model, layer_idx, filter_indices=index, \n                                   seed_input=img, backprop_modifier=modifier)   \n        ax[index].imshow(grads, cmap='jet')","metadata":{"id":"eadhHzY6Mosb","outputId":"75c1b2f7-2ece-48e7-fa24-56835d7f43db"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.cm as cm\nfrom vis.visualization import visualize_cam\n\npenultimate_layer = utils.find_layer_idx(model, 'Conv_1_bn')\n\nfor modifier in [None, 'guided', 'relu']:\n    plt.figure()\n    f, ax = plt.subplots(1, 2)\n    plt.suptitle(\"vanilla\" if modifier is None else modifier)\n    for index, img in enumerate(images_array):    \n        grads = visualize_cam(model, layer_idx, filter_indices=index, \n                              seed_input=img, penultimate_layer_idx=penultimate_layer,\n                              backprop_modifier=modifier)        \n  \n        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n        ax[index].imshow(overlay(jet_heatmap, img))","metadata":{"id":"gvPkT3QyOGvJ","outputId":"f215c8e5-138b-406e-fb54-526448beb9a0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save model","metadata":{"id":"7wlxCZPxv4Qy"}},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"malaria_model.json\", \"w\") as json_file:\n    json_file.write(model_json)","metadata":{"id":"5igZYyc7vXhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"1QfecpEcv7rr"},"execution_count":null,"outputs":[]}]}